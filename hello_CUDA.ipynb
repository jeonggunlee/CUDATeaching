{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeonggunlee/CUDATeaching/blob/master/hello_CUDA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CZGtc9NKiDI",
        "colab_type": "text"
      },
      "source": [
        "# **GPU 기반의 고성능 CUDA 프로그래밍**\n",
        "## 한림대학교 소프트웨어 융합대학 이정근\n",
        "## 2019년 2월\n",
        "\n",
        "안녕하세요. 반갑습니다. 한림대학교 소프트웨어융합대학 이정근 교수라고 합니다.\n",
        "이번 GPU CUDA 교육에 참여해 주셔서 감사합니다. 본 강의는 이론과 실습으로 이루어져 있으며, 실습은 Colab을 통해서 진행될 예정입니다.\n",
        "\n",
        "우선 교육에 참여하신 모든 선생님들께서는 Github 및 Colab 계정을 만들어 주시면 감사드리겠습니다.\n",
        "\n",
        "* Github 주소: www.github.com\n",
        "* Colab 주소: colab.research.google.com\n",
        "* Google Drive 연동 : https://github.com/jeonggunlee/CUDATeaching/blob/master/colab_gdrive.ipynb\n",
        "\n",
        "*  *  *\n",
        "\n",
        "Colab에서 CUDA Coding을 실습하기 위해서는 몇가지 사항을 알아야합니다.\n",
        "\n",
        "* [코드 셀]에서 command-line 명령어 실행시키기\n",
        "   - !ls : 현재 디렉토리의 내용을 보여준다.\n",
        "   - %cd *dir*: *dir* 디렉토리로 이동한다.\n",
        "   - %pwd: 현재 위치한 디렉토리 위치를 보여준다.\n",
        "   - !git: git 명령어를 실행시킨다.\n",
        "\n",
        "* 또한 GPU 장치와 관련되어 다음 명령어를 확인해주시기 바랍니다.\n",
        "   - !nvidia-smi: 현재 사용하고 있는 GPU의 스펙과 작동 상황을 보여준다.\n",
        "   - !nvcc: Nvidia CUDA Compiler를 실행시킨다.\n",
        "   \n",
        "위의 명령어들을 실행 시켜 보시기 바랍니다. \n",
        "\n",
        "아래의 내용은 youtube 동영상을 통하여 확인할 수 있습니다. [colab을 이용한 GPU CUDA 프로그래밍 ](https://youtu.be/pT38R3jXwe0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb77KWtoALVn",
        "colab_type": "text"
      },
      "source": [
        "처음 명령어로 pwd 명령어를 실행시켜보도록 하겠습니다. pwd는 사용자가 위치한 디렉토리를 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHD_AWXq-N_m",
        "colab_type": "code",
        "outputId": "7445a191-6e03-4c18-bf19-6ebca6df8909",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3PXHN9YAV39",
        "colab_type": "text"
      },
      "source": [
        "현재의 디렉토리가 content에 위치하고 있네요. 기본적으로 colab을 사용하는 사용자는 항상 위와 같은 위치를 초기 디렉토리로 사용하게 됩니다.\n",
        "다음으로 Unix/Linux 계열의 가장 기본적인 명령인 ls를 사용해보도록 하겠습니다. ls 명령어는 현재 디렉토리에 있는 화일 또는 디렉토리를 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEYYd1IaNw9b",
        "colab_type": "code",
        "outputId": "1c54cc56-6346-451d-a0d2-36d20f316d67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wqbULRBAwpm",
        "colab_type": "text"
      },
      "source": [
        "위에서 보는 바와 같이 sample_data라는 디렉토리가 하위 디렉토리에 있다는 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YilM6khOA4c-",
        "colab_type": "text"
      },
      "source": [
        "다음으로 우리가 사용하고 있는 시스템의 프로세서 및 GPU에 대해서 알아보도록 하지요.\n",
        "우선 CPU에 대한 정보를 얻기 위해서 Proc file 시스템의 cpuinfo를 cat 명령어로 보도록 해보지요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23SOyndQ-Te1",
        "colab_type": "code",
        "outputId": "f282071e-7fba-4fa6-b9eb-56e6107429da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 999
        }
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs itlb_multihit\n",
            "bogomips\t: 4600.00\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQLO9xU5r0FT",
        "colab_type": "text"
      },
      "source": [
        "메모리 및 디스크 사용량을 알아볼까요 ?\n",
        "\n",
        "1.   메모리 사용량: !cat /proc/meminfo\n",
        "2.   디스크 사용량: !df -h\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uixdR9Wr4Ve",
        "colab_type": "code",
        "outputId": "4a3c7292-54c6-440d-b6fb-685cf5172c38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "!df -h"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          69G   32G   34G  49% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.8G     0  5.8G   0% /dev/shm\n",
            "tmpfs           6.4G   16K  6.4G   1% /var/colab\n",
            "/dev/sda1        75G   33G   43G  44% /opt/bin\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPZ2wmn4BKPG",
        "colab_type": "text"
      },
      "source": [
        "자 다음엔 GPU의 스펙을 살펴보도록 하지요. GPU에 대한 정보를 얻기 위해서는 nvidia-smi 명령어를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlMXU3Gx-ffG",
        "colab_type": "code",
        "outputId": "5b63aaae-2baf-42ab-f64b-981b270aec03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 30 15:56:12 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bm9xIN3xBTHO",
        "colab_type": "text"
      },
      "source": [
        "CPU와 GPU에 대한 정보를 확인 한 후에는 우리가 수행하고자 하는 코드들을 github로 부터 가져와서 시행해보도록 하겠습니다.\n",
        "\n",
        "저같은 경우는 https://github.com/jeonggunlee/CUDATeaching 의 내용을 git 명령어를 통하여 clone 해오도록 하겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXFwkU-32_Qr",
        "colab_type": "code",
        "outputId": "b98d9268-cbd0-406a-9e66-fddec40aa8d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "!git clone https://github.com/jeonggunlee/CUDATeaching"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CUDATeaching'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 564 (delta 15), reused 0 (delta 0), pack-reused 536\u001b[K\n",
            "Receiving objects: 100% (564/564), 31.11 MiB | 39.63 MiB/s, done.\n",
            "Resolving deltas: 100% (308/308), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3IR5nKLBoCn",
        "colab_type": "text"
      },
      "source": [
        "Git clone이 완료된 후에 올바로 clone이 되었는지 확인하기 위하여 ls 명령어를 수행해보독 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPhAWjWE-2Hd",
        "colab_type": "code",
        "outputId": "bd82b488-7d0f-4f64-ed51-b76e4413fd25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDATeaching  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qegzQU75BvPV",
        "colab_type": "text"
      },
      "source": [
        "이후, cd 명령어를 이용하여 CUDATeaching 디렉토리로 들어가보도록 하겠습니다. 주의 할점은 시스템 명령어를 시행할때 ! 또는 %를 붙여주어야 한다는 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbnP0p_j-5k3",
        "colab_type": "code",
        "outputId": "6ec119f9-3c80-4a09-8ec7-93c0647d2881",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd CUDATeaching"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CUDATeaching\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvgc2IbkB7-Z",
        "colab_type": "text"
      },
      "source": [
        "다시 CUDATeaching 디렉토리로 들어온 후에 ls 명령어를 통하여 디렉토리에 어떤 화일이 있는지 살펴보도록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFj7PCl0_Btq",
        "colab_type": "code",
        "outputId": "593df100-70e5-48b9-b4e1-5aa59ecd73f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "00_googleDrive_CUDAExam.ipynb\t03_cuda_lab\t\t  images\n",
            "01_cuda_lab\t\t\t03_numba_vectorize.ipynb  PPTs\n",
            "01_PyCUDA_simple_example.ipynb\tcolab_gdrive.ipynb\t  README.md\n",
            "02_cuda_lab\t\t\thello_CUDA.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-YhEY8mq_v2",
        "colab_type": "text"
      },
      "source": [
        "위 화일 및 디렉토리 중,01_cuda_lab에 들어가 보도록 하겠습니다. 01_cuda_lab에는 실습을 위한 cuda 소스 코드들이 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQjjUR9-_F7c",
        "colab_type": "code",
        "outputId": "9e73bb72-e9b7-4bf9-f8d7-6eff4c8ad827",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd 01_cuda_lab"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CUDATeaching/01_cuda_lab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CUELaLGCXdu",
        "colab_type": "text"
      },
      "source": [
        "01_cuda_lab에 들어온후에 ls 명령어를 통하여 어떤 화일들이 있는지 확인해보록 하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ0EtSxX_J2l",
        "colab_type": "code",
        "outputId": "3b0a3e8d-e25c-43c1-a3f3-251775e6fb48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01_simple.ipynb      05_vectorAdd.ipynb\t\t     09_coalMemory.ipynb\n",
            "02_openmp.ipynb      06_2DIndex.ipynb\t\t     clock.cu\n",
            "03_simple_avx.ipynb  07_memoryType.ipynb\t     README.md\n",
            "04_helloCUDA.ipynb   08_DeviceQuery_Bandwidth.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S5tXs76CfYd",
        "colab_type": "text"
      },
      "source": [
        "가장 기본 적인 코드로 1hello.cu 를 컴파일 하고 실행시켜보도록 하겠습니다.\n",
        "1hello.cu의 내용은 아래와 같습니다.\n",
        "\n",
        "```cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "  printf(\"Hello thread %d in block %d\\n\", threadIdx.x, blockIdx.x);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  helloCUDA<<<3, 4>>>();\n",
        "  cudaDeviceReset();\n",
        "  return 0;\n",
        "}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gb1e6kiWTloU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a96b5635-25b5-4757-9b11-1d9f0d9efe47"
      },
      "source": [
        "%%writefile 1hello.cu\n",
        "\n",
        "# include <stdio.h>\n",
        " \n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "  printf(\"Hello thread %d in block %d\\n\", threadIdx.x, blockIdx.x);\n",
        "}\n",
        " \n",
        "int main()\n",
        "{\n",
        "  helloCUDA<<<3, 4>>>();\n",
        "  cudaDeviceReset();\n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing 1hello.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDA89RC4DIZu",
        "colab_type": "text"
      },
      "source": [
        "1hello.cu를 컴파일하기 위하여 nvdia GPU 컴파일러 명령어인 nvcc를 사용합니다.\n",
        "nvcc 컴파일러가 어디에 위치하는지 먼저 살펴볼까요 ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gXSXck4on4X",
        "colab_type": "code",
        "outputId": "db0817c9-a96a-4579-b891-b1a27e20a494",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!which nvcc"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/cuda/bin/nvcc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmW53_jZovgS",
        "colab_type": "text"
      },
      "source": [
        "위의 명령어를 통하여 nvcc 컴파일러가 /usr/local/cuda/bin/에 위치하고 있음을 알 수 있습니다.\n",
        "다음은 nvidia GPU 카드가 설치 되었는지 확인해보는 작업을 진행해보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpBm7vw9pNTy",
        "colab_type": "code",
        "outputId": "9d979cf9-730f-49e0-b9bc-3bbe28811b3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "!ls -l /dev/nv*"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "crw-rw-rw- 1 root root 195,   0 May 30 15:54 /dev/nvidia0\n",
            "crw-rw-rw- 1 root root 195, 255 May 30 15:54 /dev/nvidiactl\n",
            "crw-rw-rw- 1 root root 247,   0 May 30 15:54 /dev/nvidia-uvm\n",
            "crw-rw-rw- 1 root root 247,   1 May 30 15:54 /dev/nvidia-uvm-tools\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9_xbMo7pTXO",
        "colab_type": "text"
      },
      "source": [
        "위의 nvidia0 및 nvidiactrl 등을 통하여 nvidia GPU 장치가 설치되어 있음을 알 수 있습니다.\n",
        "\n",
        "자 그럼 장치와 컴파일러가 잘 설치되어 있음을 확인하였으니, nvcc 명령어를 이용하여 CUDA 코드를 컴파일을 해보도록 하겠습니다.\n",
        "\n",
        "명령어의 가장 단순한 컴파일 형식은 다음과 같습니다.\n",
        "   * nvcc cuda_code.cu -o executable_output\n",
        "   * 실예] nvcc ./1hello.cu -o 1hello\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8uy4sE0_NCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc ./1hello.cu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqBlBr27DPH_",
        "colab_type": "text"
      },
      "source": [
        "이후, 컴파일된 실행화일인 a.out을 실행시키면 해당 결과가 프린트 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgT2HwkN_Zvd",
        "colab_type": "code",
        "outputId": "2f1917c7-7b62-4545-e414-c626f34802c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "!./a.out"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello thread 0 in block 0\n",
            "Hello thread 1 in block 0\n",
            "Hello thread 2 in block 0\n",
            "Hello thread 3 in block 0\n",
            "Hello thread 0 in block 1\n",
            "Hello thread 1 in block 1\n",
            "Hello thread 2 in block 1\n",
            "Hello thread 3 in block 1\n",
            "Hello thread 0 in block 2\n",
            "Hello thread 1 in block 2\n",
            "Hello thread 2 in block 2\n",
            "Hello thread 3 in block 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiUlkF5gpYEP",
        "colab_type": "text"
      },
      "source": [
        "위의 코드를 수정하고 싶다면 어떻게 하면 좋을까요 ?\n",
        "\" %%writefile hello_cuda.cu \"를 이용해서 진행하면 좋을 것 같습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdLQnzbsppGF",
        "colab_type": "code",
        "outputId": "5c8c8f6c-2fe6-4bf1-c69e-02dc0419175e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile hello_cuda.cu\n",
        "# include <stdio.h>\n",
        "\n",
        "__global__ void helloCUDA(void)\n",
        "{\n",
        "  printf(\"Hello thread %d in block %d\\n\", threadIdx.x, blockIdx.x);\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "  helloCUDA<<<2, 3>>>();\n",
        "  cudaDeviceReset();\n",
        "  return 0;\n",
        "}\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting hello_cuda.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQnWq_MnqGiy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvcc ./hello_cuda.cu -o hello_cuda"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP3eh9amqYt3",
        "colab_type": "code",
        "outputId": "328d6a23-6f0e-4d3f-967b-fe2b1ad5d9f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "01_simple.ipynb      06_2DIndex.ipynb\t\t     hello_cuda\n",
            "02_openmp.ipynb      07_memoryType.ipynb\t     hello_cuda.cu\n",
            "03_simple_avx.ipynb  08_DeviceQuery_Bandwidth.ipynb  README.md\n",
            "04_helloCUDA.ipynb   09_coalMemory.ipynb\n",
            "05_vectorAdd.ipynb   clock.cu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSaBx4qHqeyw",
        "colab_type": "code",
        "outputId": "c50d5260-cdfe-48f6-9e82-d9bf07ab041b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "!./a.out"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello thread 0 in block 0\n",
            "Hello thread 1 in block 0\n",
            "Hello thread 2 in block 0\n",
            "Hello thread 3 in block 0\n",
            "Hello thread 0 in block 1\n",
            "Hello thread 1 in block 1\n",
            "Hello thread 2 in block 1\n",
            "Hello thread 3 in block 1\n",
            "Hello thread 0 in block 2\n",
            "Hello thread 1 in block 2\n",
            "Hello thread 2 in block 2\n",
            "Hello thread 3 in block 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJZLln-6DVf2",
        "colab_type": "text"
      },
      "source": [
        "오늘 colaboratory를 활용하여 간단히 GPU CUDA Programming을 하는 방법을 보여드렸습니다. 잘 활용하시면 좋을 것 같네요!\n",
        "감사합니다.\n"
      ]
    }
  ]
}